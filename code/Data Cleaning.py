import re
import unicodedata
import emoji
import pandas as pd
from unidecode import unidecode
import ftfy
from cleantext import clean
import nltk
from tqdm import tqdm
from Sastrawi.Stemmer.StemmerFactory import StemmerFactory
from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory

class JudolTextCleaner:
    def __init__(self, domain_number_strategy='preserve', number_replacement_strategy='smart'):
        """
        Initialize JudolTextCleaner
        
        Parameters:
        domain_number_strategy (str): Strategi untuk angka di domain
            - 'remove': Hapus angka di akhir (pstoto99 -> pstoto)
            - 'preserve': Pertahankan angka sebagai token terpisah (pstoto99 -> pstoto 99) [RECOMMENDED]
            - 'separate_token': Gunakan token khusus (pstoto99 -> pstoto [DOMAIN_NUMBER])
        number_replacement_strategy (str): Strategi untuk angka di tengah kata
            - 'aggressive': Ganti semua angka dengan huruf (insan4d -> insanad)
            - 'smart': Ganti hanya angka yang membentuk kata judol, pertahankan lainnya (insan4d -> insan4d) [RECOMMENDED]
            - 'preserve': Pertahankan semua angka asli
        """       

        # Initialize Sastrawi untuk bahasa Indonesia
        factory = StemmerFactory()
        self.stemmer = factory.create_stemmer()
        stopword_factory = StopWordRemoverFactory()
        self.stopword_remover = stopword_factory.create_stop_word_remover()
        
        # Strategy configuration
        self.domain_number_strategy = domain_number_strategy
        self.number_replacement_strategy = number_replacement_strategy
        
        # Mapping untuk number replacement
        self.number_map = {
            '0': 'o', '1': 'i', '2': 'z', '3': 'e', '4': 'a',
            '5': 's', '6': 'g', '7': 't', '8': 'b', '9': 'g',
            '!': 'i', '@': 'a', '$': 's', '+': 't'
        }

        # Emoji mapping untuk angka dan huruf
        self.emoji_numbers = {
            '1ï¸âƒ£': '1', '2ï¸âƒ£': '2', '3ï¸âƒ£': '3', '4ï¸âƒ£': '4', '5ï¸âƒ£': '5', 
            '6ï¸âƒ£': '6', '7ï¸âƒ£': '7', '8ï¸âƒ£': '8', '9ï¸âƒ£': '9', '0ï¸âƒ£': '0',
            'âž€': '1', 'âž': '2', 'âž‚': '3', 'âžƒ': '4', 'âž„': '5',
            'âž…': '6', 'âž†': '7', 'âž‡': '8', 'âžˆ': '9', 'ðŸ„‹': '0',
            'ðŸ¥‡': '1', 'ðŸ¥ˆ': '2', 'ðŸ¥‰': '3', 'ðŸ†': ' trophy ', 'ðŸŽ¯': ' target ',
            'â¶': '1', 'â·': '2', 'â¸': '3', 'â¹': '4', 'âº': '5',
            'â»': '6', 'â¼': '7', 'â½': '8', 'â¾': '9', 'â¿': '10',
        }
        
        self.emoji_letters = {
            'ðŸ‡¦': 'a', 'ðŸ‡§': 'b', 'ðŸ‡¨': 'c', 'ðŸ‡©': 'd', 'ðŸ‡ª': 'e',
            'ðŸ‡«': 'f', 'ðŸ‡¬': 'g', 'ðŸ‡­': 'h', 'ðŸ‡®': 'i', 'ðŸ‡¯': 'j',
            'ðŸ‡°': 'k', 'ðŸ‡±': 'l', 'ðŸ‡²': 'm', 'ðŸ‡³': 'n', 'ðŸ‡´': 'o',
            'ðŸ‡µ': 'p', 'ðŸ‡¶': 'q', 'ðŸ‡·': 'r', 'ðŸ‡¸': 's', 'ðŸ‡¹': 't',
            'ðŸ‡º': 'u', 'ðŸ‡»': 'v', 'ðŸ‡¼': 'w', 'ðŸ‡½': 'x', 'ðŸ‡¾': 'y',
            'ðŸ‡¿': 'z', 'ðŸ…°': 'a', 'ðŸ…±': 'b', 'ðŸ…²': 'c', 'ðŸ…³': 'd',
            'ðŸ…´': 'e', 'ðŸ…µ': 'f', 'ðŸ…¶': 'g', 'ðŸ…·': 'h', 'ðŸ…¸': 'i',
            'ðŸ…¹': 'j', 'ðŸ…º': 'k', 'ðŸ…»': 'l', 'ðŸ…¼': 'm', 'ðŸ…½': 'n',
            'ðŸ…¾': 'o', 'ðŸ…¿': 'p', 'ðŸ†€': 'q', 'ðŸ†': 'r', 'ðŸ†‚': 's',
            'ðŸ†ƒ': 't', 'ðŸ†„': 'u', 'ðŸ†…': 'v', 'ðŸ††': 'w', 'ðŸ†‡': 'x',
            'ðŸ†ˆ': 'y', 'ðŸ†‰': 'z', 'ðŸ…': 'a', 'ðŸ…‘': 'b', 'ðŸ…’': 'c',
            'ðŸ…“': 'd', 'ðŸ…”': 'e', 'ðŸ…•': 'f', 'ðŸ…–': 'g', 'ðŸ…—': 'h',
            'ðŸ…˜': 'i', 'ðŸ…™': 'j', 'ðŸ…š': 'k', 'ðŸ…›': 'l', 'ðŸ…œ': 'm',
            'ðŸ…': 'n', 'ðŸ…ž': 'o', 'ðŸ…Ÿ': 'p', 'ðŸ… ': 'q', 'ðŸ…¡': 'r',
            'ðŸ…¢': 's', 'ðŸ…£': 't', 'ðŸ…¤': 'u', 'ðŸ…¥': 'v', 'ðŸ…¦': 'w',
            'ðŸ…§': 'x', 'ðŸ…¨': 'y', 'ðŸ…©': 'z', 'â’¶': 'a', 'â’·': 'b',
            'â’¸': 'c', 'â’¹': 'd', 'â’º': 'e', 'â’»': 'f', 'â’¼': 'g',
            'â’½': 'h', 'â’¾': 'i', 'â’¿': 'j', 'â“€': 'k', 'â“': 'l',
            'â“‚': 'm', 'â“ƒ': 'n', 'â“„': 'o', 'â“…': 'p', 'â“†': 'q',
            'â“‡': 'r', 'â“ˆ': 's', 'â“‰': 't', 'â“Š': 'u', 'â“‹': 'v',
            'â“Œ': 'w', 'â“': 'x', 'â“Ž': 'y', 'â“': 'z',
        }

        # Leet speak patterns khusus bahasa Indonesia
        self.leet_speak_indonesia = {
            'b9s4n': 'bosan', 'b0s4n': 'bosan', 'b05an': 'bosan',
            '7un9kad': 'rungkad', 'tun9kad': 'rungkad', 'rungk4d': 'rungkad',
            'runk4d': 'rungkad', 'j04n': 'join', 'j01n': 'join',
            'buru4n': 'buruan', 'b3s4r': 'besar', 'k3c11': 'kecill',
            'murah4n': 'murahan', 'g4c0r': 'gacor', 'g4cor': 'gacor',
            'm4nt4p': 'mantap', 'm4nt4b': 'mantap', 's3r1u': 'serius',
            's3r1ous': 'serius', 'wd': 'wd', 'dp': 'deposit', 'd3p0': 'depo',
            'm4nd4ng': 'mandang', 's4k1t': 'sakit', 'b4ng3t': 'banget',
            'k3r3n': 'keren', 'h4ncur': 'hancur', 'm4ntu1': 'mantul',
            'p4st1': 'pasti', 't0p': 'top', 'pr0': 'pro', 'n0ob': 'noob',
            'c0b4': 'coba',
        }
        
        # Extended character normalization mapping - DIPERLUAS dan DIPERBAIKI
        self.extended_char_map = {
            # Latin Extended characters
            'Ã¤': 'a', 'Ã„': 'a', 'Ã¥': 'a', 'Ã…': 'a', 'Ã¦': 'ae', 'Ã†': 'ae',
            'Ã§': 'c', 'Ã‡': 'c', 'Ã°': 'd', 'Ã': 'd', 'Ã«': 'e', 'Ã‹': 'e',
            'Ã¯': 'i', 'Ã': 'i', 'Ã±': 'n', 'Ã‘': 'n', 'Ã¶': 'o', 'Ã–': 'o',
            'Ã¸': 'o', 'Ã˜': 'o', 'Ã¼': 'u', 'Ãœ': 'u', 'Ã¿': 'y', 'Å¸': 'y',
            'Å¾': 'z', 'Å½': 'z', 'Å¡': 's', 'Å ': 's', 'Ä': 'c', 'ÄŒ': 'c',
            'Ä‡': 'c', 'Ä†': 'c', 'ÄŸ': 'g', 'Äž': 'g', 'ÅŸ': 's', 'Åž': 's',
            'Ä±': 'i', 'Ä°': 'i',
            
            # Greek letters yang sering digunakan sebagai pengganti
            'Î±': 'a', 'Î²': 'b', 'Î³': 'g', 'Î´': 'd', 'Îµ': 'e', 'Î¶': 'z',
            'Î·': 'h', 'Î¸': 'th', 'Î¹': 'i', 'Îº': 'k', 'Î»': 'l', 'Î¼': 'm',
            'Î½': 'n', 'Î¾': 'x', 'Î¿': 'o', 'Ï€': 'p', 'Ï': 'r', 'Ïƒ': 's',
            'Ï„': 't', 'Ï…': 'u', 'Ï†': 'ph', 'Ï‡': 'ch', 'Ïˆ': 'ps', 'Ï‰': 'w',
            'Î‘': 'a', 'Î’': 'b', 'Î“': 'g', 'Î”': 'd', 'Î•': 'e', 'Î–': 'z',
            'Î—': 'h', 'Î˜': 'th', 'Î™': 'i', 'Îš': 'k', 'Î›': 'l', 'Îœ': 'm',
            'Î': 'n', 'Îž': 'x', 'ÎŸ': 'o', 'Î ': 'p', 'Î¡': 'r', 'Î£': 's',
            'Î¤': 't', 'Î¥': 'u', 'Î¦': 'ph', 'Î§': 'ch', 'Î¨': 'ps', 'Î©': 'w',
            
            # Cyrillic characters yang sering digunakan
            'Ð°': 'a', 'Ð±': 'b', 'Ð²': 'v', 'Ð³': 'g', 'Ð´': 'd', 'Ðµ': 'e',
            'Ñ‘': 'e', 'Ð¶': 'zh', 'Ð·': 'z', 'Ð¸': 'i', 'Ð¹': 'y', 'Ðº': 'k',
            'Ð»': 'l', 'Ð¼': 'm', 'Ð½': 'n', 'Ð¾': 'o', 'Ð¿': 'p', 'Ñ€': 'r',
            'Ñ': 's', 'Ñ‚': 't', 'Ñƒ': 'u', 'Ñ„': 'f', 'Ñ…': 'h', 'Ñ†': 'ts',
            'Ñ‡': 'ch', 'Ñˆ': 'sh', 'Ñ‰': 'sch', 'ÑŠ': '', 'Ñ‹': 'y', 'ÑŒ': '',
            'Ñ': 'e', 'ÑŽ': 'yu', 'Ñ': 'ya',
            'Ð': 'a', 'Ð‘': 'b', 'Ð’': 'v', 'Ð“': 'g', 'Ð”': 'd', 'Ð•': 'e',
            'Ð': 'e', 'Ð–': 'zh', 'Ð—': 'z', 'Ð˜': 'i', 'Ð™': 'y', 'Ðš': 'k',
            'Ð›': 'l', 'Ðœ': 'm', 'Ð': 'n', 'Ðž': 'o', 'ÐŸ': 'p', 'Ð ': 'r',
            'Ð¡': 's', 'Ð¢': 't', 'Ð£': 'u', 'Ð¤': 'f', 'Ð¥': 'h', 'Ð¦': 'ts',
            'Ð§': 'ch', 'Ð¨': 'sh', 'Ð©': 'sch', 'Ðª': '', 'Ð«': 'y', 'Ð¬': '',
            'Ð­': 'e', 'Ð®': 'yu', 'Ð¯': 'ya',
            
            # Mathematical alphanumeric symbols
            'ð€': 'a', 'ð': 'b', 'ð‚': 'c', 'ðƒ': 'd', 'ð„': 'e', 'ð…': 'f',
            'ð†': 'g', 'ð‡': 'h', 'ðˆ': 'i', 'ð‰': 'j', 'ðŠ': 'k', 'ð‹': 'l',
            'ðŒ': 'm', 'ð': 'n', 'ðŽ': 'o', 'ð': 'p', 'ð': 'q', 'ð‘': 'r',
            'ð’': 's', 'ð“': 't', 'ð”': 'u', 'ð•': 'v', 'ð–': 'w', 'ð—': 'x',
            'ð˜': 'y', 'ð™': 'z', 'ðš': 'a', 'ð›': 'b', 'ðœ': 'c', 'ð': 'd',
            'ðž': 'e', 'ðŸ': 'f', 'ð ': 'g', 'ð¡': 'h', 'ð¢': 'i', 'ð£': 'j',
            'ð¤': 'k', 'ð¥': 'l', 'ð¦': 'm', 'ð§': 'n', 'ð¨': 'o', 'ð©': 'p',
            'ðª': 'q', 'ð«': 'r', 'ð¬': 's', 'ð­': 't', 'ð®': 'u', 'ð¯': 'v',
            'ð°': 'w', 'ð±': 'x', 'ð²': 'y', 'ð³': 'z',
            
            'ð´': 'a', 'ðµ': 'b', 'ð¶': 'c', 'ð·': 'd', 'ð¸': 'e', 'ð¹': 'f',
            'ðº': 'g', 'ð»': 'h', 'ð¼': 'i', 'ð½': 'j', 'ð¾': 'k', 'ð¿': 'l',
            'ð‘€': 'm', 'ð‘': 'n', 'ð‘‚': 'o', 'ð‘ƒ': 'p', 'ð‘„': 'q', 'ð‘…': 'r',
            'ð‘†': 's', 'ð‘‡': 't', 'ð‘ˆ': 'u', 'ð‘‰': 'v', 'ð‘Š': 'w', 'ð‘‹': 'x',
            'ð‘Œ': 'y', 'ð‘': 'z', 'ð‘Ž': 'a', 'ð‘': 'b', 'ð‘': 'c', 'ð‘‘': 'd',
            'ð‘’': 'e', 'ð‘“': 'f', 'ð‘”': 'g', 'â„Ž': 'h', 'ð‘–': 'i', 'ð‘—': 'j',
            'ð‘˜': 'k', 'ð‘™': 'l', 'ð‘š': 'm', 'ð‘›': 'n', 'ð‘œ': 'o', 'ð‘': 'p',
            'ð‘ž': 'q', 'ð‘Ÿ': 'r', 'ð‘ ': 's', 'ð‘¡': 't', 'ð‘¢': 'u', 'ð‘£': 'v',
            'ð‘¤': 'w', 'ð‘¥': 'x', 'ð‘¦': 'y', 'ð‘§': 'z',
            
            'ð’œ': 'a', 'â„¬': 'b', 'ð’ž': 'c', 'ð’Ÿ': 'd', 'â„°': 'e', 'â„±': 'f',
            'ð’¢': 'g', 'â„‹': 'h', 'â„': 'i', 'ð’¥': 'j', 'ð’¦': 'k', 'â„’': 'l',
            'â„³': 'm', 'ð’©': 'n', 'ð’ª': 'o', 'ð’«': 'p', 'ð’¬': 'q', 'â„›': 'r',
            'ð’®': 's', 'ð’¯': 't', 'ð’°': 'u', 'ð’±': 'v', 'ð’²': 'w', 'ð’³': 'x',
            'ð’´': 'y', 'ð’µ': 'z', 'ð’¶': 'a', 'ð’·': 'b', 'ð’¸': 'c', 'ð’¹': 'd',
            'â„¯': 'e', 'ð’»': 'f', 'â„Š': 'g', 'ð’½': 'h', 'ð’¾': 'i', 'ð’¿': 'j',
            'ð“€': 'k', 'ð“': 'l', 'ð“‚': 'm', 'ð“ƒ': 'n', 'â„´': 'o', 'ð“…': 'p',
            'ð“†': 'q', 'ð“‡': 'r', 'ð“ˆ': 's', 'ð“‰': 't', 'ð“Š': 'u', 'ð“‹': 'v',
            'ð“Œ': 'w', 'ð“': 'x', 'ð“Ž': 'y', 'ð“': 'z',
            
            'ð“': 'a', 'ð“‘': 'b', 'ð“’': 'c', 'ð““': 'd', 'ð“”': 'e', 'ð“•': 'f',
            'ð“–': 'g', 'ð“—': 'h', 'ð“˜': 'i', 'ð“™': 'j', 'ð“š': 'k', 'ð“›': 'l',
            'ð“œ': 'm', 'ð“': 'n', 'ð“ž': 'o', 'ð“Ÿ': 'p', 'ð“ ': 'q', 'ð“¡': 'r',
            'ð“¢': 's', 'ð“£': 't', 'ð“¤': 'u', 'ð“¥': 'v', 'ð“¦': 'w', 'ð“§': 'x',
            'ð“¨': 'y', 'ð“©': 'z', 'ð“ª': 'a', 'ð“«': 'b', 'ð“¬': 'c', 'ð“­': 'd',
            'ð“®': 'e', 'ð“¯': 'f', 'ð“°': 'g', 'ð“±': 'h', 'ð“²': 'i', 'ð“³': 'j',
            'ð“´': 'k', 'ð“µ': 'l', 'ð“¶': 'm', 'ð“·': 'n', 'ð“¸': 'o', 'ð“¹': 'p',
            'ð“º': 'q', 'ð“»': 'r', 'ð“¼': 's', 'ð“½': 't', 'ð“¾': 'u', 'ð“¿': 'v',
            'ð”€': 'w', 'ð”': 'x', 'ð”‚': 'y', 'ð”ƒ': 'z',
            
            'ð”„': 'a', 'ð”…': 'b', 'â„­': 'c', 'ð”‡': 'd', 'ð”ˆ': 'e', 'ð”‰': 'f',
            'ð”Š': 'g', 'â„Œ': 'h', 'â„‘': 'i', 'ð”': 'j', 'ð”Ž': 'k', 'ð”': 'l',
            'ð”': 'm', 'ð”‘': 'n', 'ð”’': 'o', 'ð”“': 'p', 'ð””': 'q', 'â„œ': 'r',
            'ð”–': 's', 'ð”—': 't', 'ð”˜': 'u', 'ð”™': 'v', 'ð”š': 'w', 'ð”›': 'x',
            'ð”œ': 'y', 'â„¨': 'z', 'ð”ž': 'a', 'ð”Ÿ': 'b', 'ð” ': 'c', 'ð”¡': 'd',
            'ð”¢': 'e', 'ð”£': 'f', 'ð”¤': 'g', 'ð”¥': 'h', 'ð”¦': 'i', 'ð”§': 'j',
            'ð”¨': 'k', 'ð”©': 'l', 'ð”ª': 'm', 'ð”«': 'n', 'ð”¬': 'o', 'ð”­': 'p',
            'ð”®': 'q', 'ð”¯': 'r', 'ð”°': 's', 'ð”±': 't', 'ð”²': 'u', 'ð”³': 'v',
            'ð”´': 'w', 'ð”µ': 'x', 'ð”¶': 'y', 'ð”·': 'z',
            
            'ð•¬': 'a', 'ð•­': 'b', 'ð•®': 'c', 'ð•¯': 'd', 'ð•°': 'e', 'ð•±': 'f',
            'ð•²': 'g', 'ð•³': 'h', 'ð•´': 'i', 'ð•µ': 'j', 'ð•¶': 'k', 'ð•·': 'l',
            'ð•¸': 'm', 'ð•¹': 'n', 'ð•º': 'o', 'ð•»': 'p', 'ð•¼': 'q', 'ð•½': 'r',
            'ð•¾': 's', 'ð•¿': 't', 'ð–€': 'u', 'ð–': 'v', 'ð–‚': 'w', 'ð–ƒ': 'x',
            'ð–„': 'y', 'ð–…': 'z', 'ð–†': 'a', 'ð–‡': 'b', 'ð–ˆ': 'c', 'ð–‰': 'd',
            'ð–Š': 'e', 'ð–‹': 'f', 'ð–Œ': 'g', 'ð–': 'h', 'ð–Ž': 'i', 'ð–': 'j',
            'ð–': 'k', 'ð–‘': 'l', 'ð–’': 'm', 'ð–“': 'n', 'ð–”': 'o', 'ð–•': 'p',
            'ð––': 'q', 'ð–—': 'r', 'ð–˜': 's', 'ð–™': 't', 'ð–š': 'u', 'ð–›': 'v',
            'ð–œ': 'w', 'ð–': 'x', 'ð–ž': 'y', 'ð–Ÿ': 'z',
            
            'ð– ': 'a', 'ð–¡': 'b', 'ð–¢': 'c', 'ð–£': 'd', 'ð–¤': 'e', 'ð–¥': 'f',
            'ð–¦': 'g', 'ð–§': 'h', 'ð–¨': 'i', 'ð–©': 'j', 'ð–ª': 'k', 'ð–«': 'l',
            'ð–¬': 'm', 'ð–­': 'n', 'ð–®': 'o', 'ð–¯': 'p', 'ð–°': 'q', 'ð–±': 'r',
            'ð–²': 's', 'ð–³': 't', 'ð–´': 'u', 'ð–µ': 'v', 'ð–¶': 'w', 'ð–·': 'x',
            'ð–¸': 'y', 'ð–¹': 'z', 'ð–º': 'a', 'ð–»': 'b', 'ð–¼': 'c', 'ð–½': 'd',
            'ð–¾': 'e', 'ð–¿': 'f', 'ð—€': 'g', 'ð—': 'h', 'ð—‚': 'i', 'ð—ƒ': 'j',
            'ð—„': 'k', 'ð—…': 'l', 'ð—†': 'm', 'ð—‡': 'n', 'ð—ˆ': 'o', 'ð—‰': 'p',
            'ð—Š': 'q', 'ð—‹': 'r', 'ð—Œ': 's', 'ð—': 't', 'ð—Ž': 'u', 'ð—': 'v',
            'ð—': 'w', 'ð—‘': 'x', 'ð—’': 'y', 'ð—“': 'z',
            
            'ð—”': 'a', 'ð—•': 'b', 'ð—–': 'c', 'ð——': 'd', 'ð—˜': 'e', 'ð—™': 'f',
            'ð—š': 'g', 'ð—›': 'h', 'ð—œ': 'i', 'ð—': 'j', 'ð—ž': 'k', 'ð—Ÿ': 'l',
            'ð— ': 'm', 'ð—¡': 'n', 'ð—¢': 'o', 'ð—£': 'p', 'ð—¤': 'q', 'ð—¥': 'r',
            'ð—¦': 's', 'ð—§': 't', 'ð—¨': 'u', 'ð—©': 'v', 'ð—ª': 'w', 'ð—«': 'x',
            'ð—¬': 'y', 'ð—­': 'z', 'ð—®': 'a', 'ð—¯': 'b', 'ð—°': 'c', 'ð—±': 'd',
            'ð—²': 'e', 'ð—³': 'f', 'ð—´': 'g', 'ð—µ': 'h', 'ð—¶': 'i', 'ð—·': 'j',
            'ð—¸': 'k', 'ð—¹': 'l', 'ð—º': 'm', 'ð—»': 'n', 'ð—¼': 'o', 'ð—½': 'p',
            'ð—¾': 'q', 'ð—¿': 'r', 'ð˜€': 's', 'ð˜': 't', 'ð˜‚': 'u', 'ð˜ƒ': 'v',
            'ð˜„': 'w', 'ð˜…': 'x', 'ð˜†': 'y', 'ð˜‡': 'z',
            
            'ð˜ˆ': 'a', 'ð˜‰': 'b', 'ð˜Š': 'c', 'ð˜‹': 'd', 'ð˜Œ': 'e', 'ð˜': 'f',
            'ð˜Ž': 'g', 'ð˜': 'h', 'ð˜': 'i', 'ð˜‘': 'j', 'ð˜’': 'k', 'ð˜“': 'l',
            'ð˜”': 'm', 'ð˜•': 'n', 'ð˜–': 'o', 'ð˜—': 'p', 'ð˜˜': 'q', 'ð˜™': 'r',
            'ð˜š': 's', 'ð˜›': 't', 'ð˜œ': 'u', 'ð˜': 'v', 'ð˜ž': 'w', 'ð˜Ÿ': 'x',
            'ð˜ ': 'y', 'ð˜¡': 'z', 'ð˜¢': 'a', 'ð˜£': 'b', 'ð˜¤': 'c', 'ð˜¥': 'd',
            'ð˜¦': 'e', 'ð˜§': 'f', 'ð˜¨': 'g', 'ð˜©': 'h', 'ð˜ª': 'i', 'ð˜«': 'j',
            'ð˜¬': 'k', 'ð˜­': 'l', 'ð˜®': 'm', 'ð˜¯': 'n', 'ð˜°': 'o', 'ð˜±': 'p',
            'ð˜²': 'q', 'ð˜³': 'r', 'ð˜´': 's', 'ð˜µ': 't', 'ð˜¶': 'u', 'ð˜·': 'v',
            'ð˜¸': 'w', 'ð˜¹': 'x', 'ð˜º': 'y', 'ð˜»': 'z',
            
            'ð˜¼': 'a', 'ð˜½': 'b', 'ð˜¾': 'c', 'ð˜¿': 'd', 'ð™€': 'e', 'ð™': 'f',
            'ð™‚': 'g', 'ð™ƒ': 'h', 'ð™„': 'i', 'ð™…': 'j', 'ð™†': 'k', 'ð™‡': 'l',
            'ð™ˆ': 'm', 'ð™‰': 'n', 'ð™Š': 'o', 'ð™‹': 'p', 'ð™Œ': 'q', 'ð™': 'r',
            'ð™Ž': 's', 'ð™': 't', 'ð™': 'u', 'ð™‘': 'v', 'ð™’': 'w', 'ð™“': 'x',
            'ð™”': 'y', 'ð™•': 'z', 'ð™–': 'a', 'ð™—': 'b', 'ð™˜': 'c', 'ð™™': 'd',
            'ð™š': 'e', 'ð™›': 'f', 'ð™œ': 'g', 'ð™': 'h', 'ð™ž': 'i', 'ð™Ÿ': 'j',
            'ð™ ': 'k', 'ð™¡': 'l', 'ð™¢': 'm', 'ð™£': 'n', 'ð™¤': 'o', 'ð™¥': 'p',
            'ð™¦': 'q', 'ð™§': 'r', 'ð™¨': 's', 'ð™©': 't', 'ð™ª': 'u', 'ð™«': 'v',
            'ð™¬': 'w', 'ð™­': 'x', 'ð™®': 'y', 'ð™¯': 'z',
            
            'ð™°': 'a', 'ð™±': 'b', 'ð™²': 'c', 'ð™³': 'd', 'ð™´': 'e', 'ð™µ': 'f',
            'ð™¶': 'g', 'ð™·': 'h', 'ð™¸': 'i', 'ð™¹': 'j', 'ð™º': 'k', 'ð™»': 'l',
            'ð™¼': 'm', 'ð™½': 'n', 'ð™¾': 'o', 'ð™¿': 'p', 'ðš€': 'q', 'ðš': 'r',
            'ðš‚': 's', 'ðšƒ': 't', 'ðš„': 'u', 'ðš…': 'v', 'ðš†': 'w', 'ðš‡': 'x',
            'ðšˆ': 'y', 'ðš‰': 'z', 'ðšŠ': 'a', 'ðš‹': 'b', 'ðšŒ': 'c', 'ðš': 'd',
            'ðšŽ': 'e', 'ðš': 'f', 'ðš': 'g', 'ðš‘': 'h', 'ðš’': 'i', 'ðš“': 'j',
            'ðš”': 'k', 'ðš•': 'l', 'ðš–': 'm', 'ðš—': 'n', 'ðš˜': 'o', 'ðš™': 'p',
            'ðšš': 'q', 'ðš›': 'r', 'ðšœ': 's', 'ðš': 't', 'ðšž': 'u', 'ðšŸ': 'v',
            'ðš ': 'w', 'ðš¡': 'x', 'ðš¢': 'y', 'ðš£': 'z',
            
            # Special symbols and brackets
            'ã€': ' ', 'ã€‘': ' ', 'ã€Ž': ' ', 'ã€': ' ', 'ã€–': ' ', 'ã€—': ' ',
            'ã€Œ': ' ', 'ã€': ' ', 'ï½¢': ' ', 'ï½£': ' ', 'ã€”': ' ', 'ã€•': ' ',
            'ã€ˆ': ' ', 'ã€‰': ' ', 'ã€Š': ' ', 'ã€‹': ' ', 'Â«': ' ', 'Â»': ' ',
            'ã€': ' ', 'ã€ž': ' ', 'ï¼‚': ' ', 'â€Ÿ': ' ', 'ã€Ÿ': ' ',
            'ï¼š': ' ', 'ï¼›': ' ', 'ï¼Œ': ' ', 'ã€‚': ' ', 'ã€': ' ',
            'ï¼': ' ', 'ï¼Ÿ': ' ', 'ï½ž': ' ', 'â€§': ' ', 'ãƒ»': ' ',
            'Â¢': ' ', '@': ' ', 'Â®': ' ', 'Â©': ' ', 'â„¢': ' ', '?': ' ',
            'â™œ': ' ', 'â˜†': ' ', 'ðŸŽ¯': ' ', 'ðŸŸ': ' ', 'âˆ': ' ', 'âœ·': ' ',
            'ðŸŽ€': ' ', 'ðŸ’®': 'o', 'ðŸµ': 'o', '|': ' ', '!': ' ', 'Â¤': ' ',
            '*': ' ', "'": ' ', '~': ' ', '`': ' ', 'Â¯': ' ', 'â€¢': ' ', 
            ',': ' ', 'Â¸': ' ', 'Â´': ' ', 'Î”': 'a', 'á—¯': 'w', 'á—©': 'a',
            'â€ ': 't', 'ä¸…': 't', 'â“„': 'o', '~': ' ', '`': ' ', 'Â´': ' ',
            
            # TAMBAHAN BARU UNTUK PERBAIKAN ARWANATOTO:
            # Greek and special characters untuk "arwanatoto"
            'Å˜': 'r', 'Î¬': 'a', 
            'ÇŸ': 'a', 'Ê€': 'r', 'Õ¡': 'w', 'Õ¼': 'n', 'È¶': 't', 'Ö…': 'o',
            'Ã±': 'n', 
            'AÒ‰': 'a', 'RÒ‰': 'r', 'WÒ‰': 'w', 'NÒ‰': 'n', 'TÒ‰': 't', 'OÒ‰': 'o',
            
            # Special decorated characters
            'ð’œ': 'a', 'ð‘…': 'r', 'ð’²': 'w', 'ð’œ': 'a', 'ð’©': 'n', 'ð’¯': 't', 
            'ðŸ’®': 'o', 'ðŸµ': 'o', 'ðŸ¬': 'o', 'â™¡': 'o', 'ðŸ’ž': 'o',
            
            # Mathematical symbols
            'ð€': 'a', 'ð‘': 'r', 'ð–': 'w', 'ð€': 'a', 'ð': 'n', 'ð“': 't', 'ðŽ': 'o',
            'ð“': 'a', 'ð“¡': 'r', 'ð“¦': 'w', 'ð“': 'a', 'ð“': 'n', 'ð“£': 't', 'ð“ž': 'o',
            'ð”„': 'a', 'â„œ': 'r', 'ð”š': 'w', 'ð”„': 'a', 'ð”‘': 'n', 'ð”—': 't', 'ð”’': 'o',
            
            # Tambahkan lebih banyak variant
            'ðŸ…': 'a', 'ðŸ…¡': 'r', 'ðŸ…¦': 'w', 'ðŸ…': 'n', 'ðŸ…£': 't', 'ðŸ…ž': 'o',
            'â’¶': 'a', 'â“‡': 'r', 'â“Œ': 'w', 'â“ƒ': 'n', 'â“‰': 't', 'â“„': 'o',
            
            # Special case characters
            'Ïƒ': 'o', 'ð“½': 't', 'ðŽ': 'o', 'ð•’': 'a', 'Ñ‚': 't', 'Î®': 'n',
            
            # Emoji dan simbol khusus
            'ðŸ¥‡': '1', 'ðŸ†': ' trophy ', 'ðŸŽ¯': ' target ', 'ðŸ’Ž': ' diamond ',
            'ðŸ’°': ' money ', 'ðŸ’¸': ' money ', 'ðŸ¤‘': ' money ', 'ðŸ’µ': ' money ',
            'ðŸ’´': ' money ', 'ðŸ’¶': ' money ', 'ðŸ’·': ' money ', 'ðŸ’³': ' card ',
            'ðŸ’¹': ' chart ', 'â†—': ' up ', 'â¬†': ' up ', 'â†˜': ' down ', 
            'â¬‡': ' down ', 'â¬…': ' left ', 'âž¡': ' right ', 'â†”': ' both ',
            'ðŸ”': ' top ', 'ðŸ”™': ' back ', 'ðŸ”›': ' on ', 'ðŸ”œ': ' soon ',
            'ðŸ”š': ' end ', 'âœ…': ' yes ', 'âœ”': ' yes ', 'âœ“': ' yes ',
            'âŒ': ' no ', 'âœ–': ' no ', 'âŽ': ' no ', 'âš ': ' warning ',
        }

        # Common judol domains untuk pattern recognition
        self.judol_domains = [
            'pstoto', 'toto', 'slot', 'poker', 'judi', 'bonus', 'arwana', 
            'pulau', 'win', 'casino', 'situs', 'bandar', 'sabung', 'taruhan',
            'insan', 'lazadatoto', 'paste4d', 'pandora4d', 'naga4d', 'hoki4d',
            'sendal4d', 'garudahoki', 'togel62', 'arwanatoto', 'pstoto99',
            'sgi88', 'sgi', 'sg188', 'sgi808', 'sgi888', 'sekali4d'  # TAMBAHKAN SEKALI4D
        ]

        # Brand names yang harus dipertahankan sebagai SATU KATA - DIPERBAIKI
        self.preserved_brands = {
            'insan4d': 'insan4d', 'pandora4d': 'pandora4d', 'naga4d': 'naga4d',
            'hoki4d': 'hoki4d', 'jaya4d': 'jaya4d', 'mega4d': 'mega4d',
            'super4d': 'super4d', 'lazadatoto': 'lazadatoto', 'lazada4d': 'lazada4d',
            'lazada88': 'lazada88', 'lazada77': 'lazada77', 'paste4d': 'paste4d',
            'pstoto99': 'pstoto99', 'pstoto88': 'pstoto88', 'pstoto77': 'pstoto77',
            'arwanatoto': 'arwanatoto', 'pulauwin': 'pulauwin', 'sendal4d': 'sendal4d',
            'garudahoki': 'garudahoki', 'togel62': 'togel62', 
            'sgi88': 'sgi88', 'sg188': 'sg188', 'sgi808': 'sgi808', 'sgi888': 'sgi888',
            'pstoto': 'pstoto', 'sekali4d': 'sekali4d'  # TAMBAHKAN SEKALI4D
        }

        # Common judol words untuk reconstruction - DIPERBAIKI
        self.judol_words_for_reconstruction = [
            'pulauwin', 'pulau', 'win', 'arwanatoto', 'arwana', 'toto',
            'lazadatoto', 'lazada', 'pstoto', 'pstoto99', 'pstoto88', 'pstoto77',
            'insan4d', 'pandora4d', 'paste4d', 'situs', 'slot', 'judi', 'togel', 
            'poker', 'bonus', 'deposit', 'withdraw', 'jackpot', 'freespin', 
            'casino', 'bandar', 'sabung', 'taruhan', 'rungkad', 'bosan', 'join', 
            'buruan', 'gacor', 'mantap', 'sendal4d', 'garudahoki', 'garuda', 
            'hoki', 'togel62', 'sgi88', 'sgi', 'sg188', 'sgi808', 'sgi888',
            'sekali4d'  # TAMBAHKAN SEKALI4D
        ]

        # Words yang mengandung angka tapi harus dipertahankan (brand names dengan angka) - DIPERBAIKI
        self.preserve_number_words = {
            'sendal4d', 'insan4d', 'pandora4d', 'naga4d', 'hoki4d', 'jaya4d',
            'mega4d', 'super4d', 'lazada4d', 'paste4d', 'pstoto99', 'pstoto88', 'pstoto77',
            'lazada88', 'garudahoki', 'togel62', 
            'sgi88', 'sg188', 'sgi808', 'sgi888', 'sekali4d'  # TAMBAHKAN SEKALI4D
        }

        # Common word combinations yang sering dipisah - DIPERBAIKI
        self.common_combinations = {
            'ga ruda ho ki': 'garudahoki',
            'ga ruda hoki': 'garudahoki',
            'garuda ho ki': 'garudahoki',
            'garuda hoki': 'garudahoki',
            'ga rudahoki': 'garudahoki',
            'pula uwin': 'pulauwin',
            'pulau win': 'pulauwin',
            'arwana toto': 'arwanatoto',
            'arwana to to': 'arwanatoto',
            'lazada toto': 'lazadatoto',
            'sendal 4d': 'sendal4d',
            'insan 4d': 'insan4d',
            'togel 62': 'togel62',
            'psto to': 'pstoto',
            'pstoto 99': 'pstoto99',
            'ps toto': 'pstoto',
            'sgi 88': 'sgi88',
            'sg 188': 'sg188',
            'sgi 808': 'sgi808',
            'sgi 888': 'sgi888',
            'di sgi88': 'di sgi88',
            'di pstoto99': 'di pstoto99',
            'sekali 4d': 'sekali4d',  # TAMBAHKAN SEKALI4D
        }

        # IMPORTANT WORDS yang TIDAK BOLEH dihapus oleh stopword removal
        self.important_words = {
            'saya', 'kamu', 'dia', 'kami', 'kita', 'mereka', 'ini', 'itu',
            'harapan', 'cuman', 'hanya', 'sekali', 'selalu', 'pernah', 'ingin',
            'mau', 'akan', 'bisa', 'dapat', 'boleh', 'harus', 'perlu', 'bisa',
            'membuat', 'menjadi', 'ubah', 'transformasi', 'dari', 'jadi',
            'pengantar', 'surat', 'manajer', 'direktur', 'bos', 'ketua',
            'manager', 'karyawan', 'pegawai', 'kerja', 'pekerjaan',
            'transaksi', 'deposit', 'withdraw', 'bonus', 'jackpot',
            'menang', 'kalah', 'untung', 'rugi', 'profit', 'hasil',
            'bertransformasi', 'berubah', 'hidup', 'nasib', 'kehidupan',
            'kaya', 'miskin', 'sukses', 'gagal', 'berhasil', 'pendapatan',
            'penghasilan', 'gaji', 'uang', 'duit', 'modal', 'investasi'
        }

        # Custom stopword list yang lebih selektif
        self.custom_stopwords = {
            'yang', 'di', 'ke', 'dari', 'pada', 'dalam', 'untuk', 'dengan', 
            'adalah', 'atau', 'tapi', 'dan', 'jika', 'karena', 'serta', 
            'oleh', 'itu', 'ini', 'saja', 'hanya', 'pun', 'lah', 'kah',
            'tah', 'pun', 'nya', 'ku', 'mu', 'kau', 'kami', 'kita', 'mereka',
            'saya', 'kamu', 'dia', 'beliau', 'para', 'si', 'sang', 'itu',
            'hal', 'per', 'oleh', 'agar', 'supaya', 'meski', 'walau',
            'sebab', 'karena', 'jika', 'kalau', 'apabila', 'seandainya',
            'agar', 'supaya', 'guna', 'untuk', 'demi', 'sebagai', 'laksana',
            'bak', 'ibarat', 'serupa', 'tanpa', 'dengan', 'secara', 'sambil',
            'seraya', 'selagi', 'sementara', 'ketika', 'tatkala', 'sewaktu',
            'sebelum', 'sesudah', 'setelah', 'hingga', 'sampai', 'semenjak',
            'sedari', 'seraya', 'sambil', 'seraya', 'sambil', 'seraya'
        }

    # ===== IMPROVED STOPWORD REMOVAL =====
    def selective_stopword_removal(self, text):
        """Stopword removal yang selektif - hanya menghapus stopwords umum"""
        words = text.split()
        filtered_words = []
        
        for word in words:
            # Jangan hapus jika:
            # 1. Termasuk important words
            # 2. Adalah brand/judol word  
            # 3. Mengandung angka
            # 4. Panjang kata > 3 karakter
            # 5. Bukan stopword custom
            word_lower = word.lower()
            if (word_lower in self.important_words or
                any(brand in word_lower for brand in self.preserved_brands) or
                any(char.isdigit() for char in word) or
                len(word) > 3 or
                word_lower not in self.custom_stopwords):
                filtered_words.append(word)
        
        return ' '.join(filtered_words)

    # ===== IMPROVED WORD SEGMENTATION =====
    def improved_word_segmentation(self, text):
        """Segmentasi kata yang lebih baik untuk kasus seperti 'disgi88membuat'"""
        # Pattern untuk memisahkan kata yang menempel pada brand
        patterns = [
            # Kasus: prefix + brand + kata (disgi88membuat -> di sgi88 membuat)
            (r'(\b\w{1,2})(sgi88|sg188|sgi808|sgi888)(\w+)\b', r'\1 \2 \3'),
            (r'(\b\w{1,2})(pstoto|arwanatoto|garudahoki)(\w+)\b', r'\1 \2 \3'),
            
            # Kasus: kata + brand (membuatsgi88 -> membuat sgi88)
            (r'(\b\w+)(sgi88|sg188|sgi808|sgi888)(\w{1,2}\b)', r'\1 \2 \3'),
            (r'(\b\w+)(pstoto|arwanatoto|garudahoki)(\w{1,2}\b)', r'\1 \2 \3'),
            
            # Kasus: brand langsung gabung dengan kata
            (r'\b(sgi88|sg188|sgi808|sgi888)(\w{3,})\b', r'\1 \2'),
            (r'\b(\w{3,})(sgi88|sg188|sgi808|sgi888)\b', r'\1 \2'),
            
            # âœ… PERBAIKI: Pattern untuk Togel62, Sendal4d, Sekali4d - LEBIH SPESIFIK
            # Kasus: kata + togel62 (membuattogel62 -> membuat togel62)
            (r'\b(\w{3,})(togel62)(\w*)\b', r'\1 \2 \3'),
            # Kasus: togel62 + kata (togel62membuat -> togel62 membuat)  
            (r'\b(togel62)(\w{3,})\b', r'\1 \2'),
            # Kasus: prefix pendek + togel62 (ditogel62 -> di togel62)
            (r'\b(\w{1,2})(togel62)(\w*)\b', r'\1 \2 \3'),
            
            # Pattern yang sama untuk sendal4d dan sekali4d
            (r'\b(\w{3,})(sendal4d)(\w*)\b', r'\1 \2 \3'),
            (r'\b(sendal4d)(\w{3,})\b', r'\1 \2'),
            (r'\b(\w{1,2})(sendal4d)(\w*)\b', r'\1 \2 \3'),
            
            (r'\b(\w{3,})(sekali4d)(\w*)\b', r'\1 \2 \3'),
            (r'\b(sekali4d)(\w{3,})\b', r'\1 \2'),
            (r'\b(\w{1,2})(sekali4d)(\w*)\b', r'\1 \2 \3'),
            
            # Kasus umum: prefix + kata
            (r'\b(di)(\w{3,})\b', r'\1 \2'),  # dimembuat -> di membuat
            (r'\b(ke)(\w{3,})\b', r'\1 \2'),  # kemana -> ke mana
            (r'\b(se)(\w{3,})\b', r'\1 \2'),  # semahal -> se mahal
        ]
        
        for pattern, replacement in patterns:
            text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)
        
        return text

    def fix_broken_alphanumeric(self, text):
        """
        Gabungkan huruf yang salah terpisah sebelum angka,
        misal 'se ru69' -> 'seru69', 'ju di777' -> 'judi777',
        tapi jangan gabungkan stopword seperti 'di', 'ke', 'yang', dll.
        """
        avoid_words = r'(di|ke|yang|aja|lagi|dan|itu|nya|bos|slot|jackpot|main|udah)'
        
        # Pastikan brand tetap utuh (tidak tergabung)
        for brand in getattr(self, "preserved_brands", []):
            text = re.sub(
                rf'\b([a-z]+)\s+({brand})\b',
                r'\1 \2',
                text,
                flags=re.IGNORECASE
            )
        
        # ðŸ”§ 1. Gabungkan tiga token sebelum angka (contoh: se ru 69 -> seru69)
        text = re.sub(
            r'\b([a-z]{1,3})\s+([a-z]{1,3})\s+([a-z]{1,3})(?=\d)',
            lambda m: m.group(1) + m.group(2) + m.group(3),
            text
        )
        
        # ðŸ”§ 2. Gabungkan dua token sebelum angka (contoh: se ru69 -> seru69)
        text = re.sub(
            r'\b([a-z]{1,4})\s+([a-z]{1,4})(?=\d)',
            lambda m: m.group(1) + m.group(2),
            text
        )
        
        # ðŸ”§ 3. Gabungkan angka yang terpisah (6 9 -> 69)
        text = re.sub(r'(\d)\s+(\d)', r'\1\2', text)
        
        return text



    def fix_spaced_letters_with_numbers(self, text):
        """
        Gabungkan huruf-huruf yang terpisah satu-satu diikuti angka.
        Contoh: 's u k u 8 8' -> 'suku88'
        """
        # Gabungkan huruf yang terpisah satu spasi
        text = re.sub(r'\b(?:([a-z])\s+){2,}([a-z])\b', 
                      lambda m: ''.join(m.group(0).split()), 
                      text)
        # Gabungkan angka yang terpisah satu spasi
        text = re.sub(r'(\d)\s+(\d)', r'\1\2', text)
        return text

    # ===== TEXT DECORATION CLEANING =====
    def remove_text_decorations(self, text):
        """Hapus dekorasi teks seperti |!Â¤*'~``~'*Â¤!| dan sejenisnya"""
        # Pattern untuk decorated text dengan berbagai simbol
        decoration_patterns = [
            r'[|!Â¤*\'~`Â¯,Â¸Ã¸ÂºÂ°âˆ™â–ªâ– â–¡â–¢â–£â–¤â–¥â–¦â–§â–¨â–©â–ªâ–«â–¬â–­â–®â–¯â–°â–±â–²â–³â–´â–µâ–¶â–·â–¸â–¹â–ºâ–»â–¼â–½â–¾â–¿â—€â—â—‚â—ƒâ—„â—…â—†â—‡â—ˆâ—‰â—Šâ—‹â—Œâ—â—Žâ—â—â—‘â—’â—“â—”â—•â—–â——â—˜â—™â—šâ—›â—œâ—â—žâ—Ÿâ— â—¡â—¢â—£â—¤â—¥â—¦â—§â—¨â—©â—ªâ—«â—¬â—­â—®â—¯â—°â—±â—²â—³â—´â—µâ—¶â—·â—¸â—¹â—ºâ—»â—¼â—½â—¾â—¿]+',
        ]
        
        for pattern in decoration_patterns:
            text = re.sub(pattern, ' ', text)
        
        return text

    # ===== EMOJI HANDLING METHODS =====
    def replace_emoji_numbers(self, text):
        """Ganti emoji angka dengan angka biasa"""
        for emoji_num, normal_num in self.emoji_numbers.items():
            text = text.replace(emoji_num, normal_num)
        return text

    def replace_emoji_letters(self, text):
        """Ganti emoji huruf dengan huruf biasa"""
        for emoji_letter, normal_letter in self.emoji_letters.items():
            text = text.replace(emoji_letter, normal_letter)
        return text

    def handle_emoji_characters(self, text):
        """Handle semua jenis emoji karakter"""
        # Step 1: Replace emoji numbers
        text = self.replace_emoji_numbers(text)
        
        # Step 2: Replace emoji letters  
        text = self.replace_emoji_letters(text)
        
        # Step 3: Remove remaining emojis, tapi pertahankan makna
        text = emoji.demojize(text)
        text = re.sub(r':[a-z_]+:', ' ', text)  # Hapus kode emoji
        
        return text

    # ===== BASIC CLEANING METHODS =====
    def remove_emojis(self, text):
        """Hapus semua emoji dan simbol"""
        return emoji.replace_emoji(text, replace=' ')

    def fix_encoding(self, text):
        """Perbaiki encoding issues"""
        return ftfy.fix_text(text)

    def normalize_unicode(self, text):
        """Normalisasi karakter unicode"""
        return unicodedata.normalize('NFKD', text)

    def remove_special_chars(self, text):
        """Hapus karakter khusus tapi pertahankan huruf Indonesia"""
        # Pertahankan kata dengan angka (brand names)
        text = re.sub(r'[^\w\s\d]', ' ', text)
        return text

    def remove_urls(self, text):
        """Hapus URL dan domain"""
        text = re.sub(r'http\S+|www\.\S+', '', text)
        text = re.sub(r'\S+\.(com|net|org|id|io)\S*', '', text)
        return text

    def remove_phone_numbers(self, text):
        """Hapus nomor telepon"""
        text = re.sub(r'[\+]?[0-9]{2,}[\s\-]?[0-9]{2,}[\s\-]?[0-9]{2,}[\s\-]?[0-9]{2,}', '', text)
        return text

    def clean_whitespace_characters(self, text):
        """Bersihkan karakter whitespace tidak terlihat"""
        text = re.sub(r'[\u200B-\u200D\uFEFF]', '', text)
        text = re.sub(r'&nbsp;', ' ', text)
        return text

    # ===== IMPROVED CHARACTER NORMALIZATION =====
    def enhanced_character_normalization(self, text):
        """Normalisasi karakter extended dan khusus dengan lebih baik"""
        # Step 1: Handle emoji characters first
        text = self.handle_emoji_characters(text)
        
        # Step 2: Normalize Unicode (NFKD untuk memisahkan diacritics)
        text = unicodedata.normalize('NFKD', text)
        
        # Step 3: Replace extended characters
        for char, replacement in self.extended_char_map.items():
            text = text.replace(char, replacement)
        
        # Step 4: Remove diacritics (accents)
        text = ''.join(c for c in text if not unicodedata.combining(c))
        
        # Step 5: Use unidecode untuk karakter yang tersisa
        text = unidecode(text)
        
        # Step 6: Remove extra spaces
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text

    def clean_brackets_and_special_chars(self, text):
        """Bersihkan brackets dan karakter khusus secara terpisah"""
        # Hapus semua brackets dan karakter khusus, ganti dengan spasi
        text = re.sub(r'[ã€ã€‘ã€Žã€ã€–ã€—ã€Œã€ï½¢ï½£ã€”ã€•ã€ˆã€‰ã€ŠÂ»Â«ã€ã€žï¼‚â€Ÿã€Ÿï¼šï¼›ï¼Œã€‚ã€ï¼ï¼Ÿï½žâ€§ãƒ»Â¢@Â®Â©â„¢]', ' ', text)
        return text

    # ===== IMPROVED BRAND RECOGNITION =====
    def enhanced_brand_recognition(self, text):
        """Enhanced brand recognition dengan pattern matching yang lebih kuat"""
        brand_patterns = {
            # SGI88 variations
            r'\b[sS5][gG9][iI1]88\b': 'sgi88',
            r'\b[sS5][gG9][iI1]\s*88\b': 'sgi88', 
            r'\b[sS5][gG9][iI1]808\b': 'sgi808',
            r'\b[sS5][gG9][iI1]888\b': 'sgi888',
            r'\b[sS5][gG9]188\b': 'sg188',
            r'\b[sS5][gG9]\s*188\b': 'sg188',
            
            # PSTOTO99 variations
            r'\b[pP][sS5][tT7][oO0][tT7][oO0]99\b': 'pstoto99',
            r'\b[pP][sS5][tT7][oO0][tT7][oO0]\s*99\b': 'pstoto99',
            r'\bpstoto\s*99\b': 'pstoto99',
            
            # âœ… PERBAIKI: Togel62 variations - HAPUS pattern spacing di sini
            r'\b[tT7][oO0][gG9][eE3][lL1]62\b': 'togel62',
            r'\b[tT7][oO0][gG9][eE3][lL1]\s*62\b': 'togel62',
            
            # Sendal4d variations
            r'\b[sS5][eE3][nN][dD][aA4@][lL1]4[dD]\b': 'sendal4d',
            r'\b[sS5][eE3][nN][dD][aA4@][lL1]\s*4[dD]\b': 'sendal4d',
            
            # Sekali4d variations
            r'\b[sS5][eE3][kK][aA4@][lL1][iI1]4[dD]\b': 'sekali4d',
            r'\b[sS5][eE3][kK][aA4@][lL1][iI1]\s*4[dD]\b': 'sekali4d',
            
            # Pattern lainnya tetap sama...
        }
        
        for pattern, replacement in brand_patterns.items():
            text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)
        
        return text

    # ===== BRAND PATTERN HANDLING =====
    def fix_specific_brand_patterns(self, text):
        """Perbaiki pattern brand khusus"""
        # Pattern untuk brackets dan special characters - HAPUS saja
        bracket_patterns = [
            r'ã€.*?ã€‘', r'ã€Ž.*?ã€', r'ã€–.*?ã€—', r'ã€Œ.*?ã€', r'ï½¢.*?ï½£',
            r'ã€”.*?ã€•', r'ã€ˆ.*?ã€‰', r'ã€Š.*?ã€‹', r'Â«.*?Â»', r'@Â¢', r'Â®', r'Â©', r'â„¢'
        ]
        
        for pattern in bracket_patterns:
            text = re.sub(pattern, ' ', text)
        
        # Pattern untuk brand names - NORMALIZE tapi pertahankan sebagai SATU KATA
        brand_patterns = {
            # SGI88 patterns - DIPERBAIKI
            r'sgi\s*88': 'sgi88',
            r'sg\s*188': 'sg188', 
            r'sgi\s*808': 'sgi808',
            r'sgi\s*888': 'sgi888',
            
            # PSTOTO99 patterns - DIPERBAIKI
            r'pstoto\s*99': 'pstoto99',
            r'ps\s*toto\s*99': 'pstoto99',
            
            # Togel62 patterns - TAMBAHKAN
            r'togel\s*62': 'togel62',
            r't0gel\s*62': 'togel62',
            
            # Sendal4d patterns - TAMBAHKAN
            r'sendal\s*4d': 'sendal4d',
            r'sendal\s*4\s*d': 'sendal4d',
            
            # Sekali4d patterns - TAMBAHKAN
            r'sekali\s*4d': 'sekali4d',
            r'sekali\s*4\s*d': 'sekali4d',
            
            # "cari di google" -> pisah menjadi 3 kata terpisah
            r'cari\s*di\s*google': 'cari di google',
            r'cari\s*di\s*g[o0][o0]gle': 'cari di google',
            r'Ã§Ã¤ri\s*di\s*gÃ¶Ã¶gle': 'cari di google',
            r'Ã§ari\s*di\s*google': 'cari di google',
            
            # "lazadatoto" -> pertahankan sebagai SATU KATA
            r'lazada\s*toto': 'lazadatoto',
            r'lazada\s*t[o0]t[o0]': 'lazadatoto',
            r'lazada\s*4d': 'lazada4d',
            
            # "garudahoki" -> pertahankan sebagai SATU KATA
            r'ga\s*ruda\s*ho\s*ki': 'garudahoki',
            r'ga\s*ruda\s*hoki': 'garudahoki',
            r'garuda\s*ho\s*ki': 'garudahoki',
            r'garuda\s*hoki': 'garudahoki',
        }
        
        for pattern, replacement in brand_patterns.items():
            text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)
        
        return text

    def fix_brand_spacing(self, text):
        """Perbaiki spacing khusus untuk brand names - VERSI DIPERBAIKI"""
        # Pattern untuk memastikan brand names memiliki spasi yang tepat
        brand_spacing_patterns = {
            # âœ… PERBAIKI: Gunakan word boundaries dan pastikan spasi konsisten
            r'\b(\w{2,})(togel62|sendal4d|sekali4d|sgi88|sg188|sgi808|sgi888|pstoto99)\b': r'\1 \2',
            r'\b(togel62|sendal4d|sekali4d|sgi88|sg188|sgi808|sgi888|pstoto99)(\w{2,})\b': r'\1 \2',
            
            # Handle kasus khusus dengan karakter tunggal
            r'\b(\w{1})(togel62|sendal4d|sekali4d)\b': r'\1 \2',
            r'\b(togel62|sendal4d|sekali4d)(\w{1})\b': r'\1 \2',
        }
        
        for pattern, replacement in brand_spacing_patterns.items():
            text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)
        
        return text

    def preserve_brand_names_in_text(self, text):
        """Pertahankan brand names sebagai satu kata dalam teks - VERSI DIPERBAIKI"""
        # âœ… PERBAIKI: Jangan tambahkan brand baru di sini, gunakan yang sudah ada di __init__
        
        # Normalize spacing terlebih dahulu
        text = re.sub(r'\s+', ' ', text).strip()
        
        # Urutkan dari yang terpanjang ke terpendek untuk menghindari partial matching
        sorted_brands = sorted(self.preserved_brands.keys(), key=len, reverse=True)
        
        for brand in sorted_brands:
            preserved_form = self.preserved_brands[brand]
            
            # âœ… PERBAIKI: Gunakan pattern yang lebih spesifik
            # Pattern 1: Brand sebagai kata utuh dengan boundaries
            pattern1 = r'\b' + re.escape(brand) + r'\b'
            text = re.sub(pattern1, preserved_form, text, flags=re.IGNORECASE)
            
            # Pattern 2: Brand dengan spasi internal (sgi 88 -> sgi88)
            if any(char.isdigit() for char in brand):
                # Untuk brand dengan angka, buat pattern dengan optional spaces
                chars = list(brand)
                spaced_pattern = r'\s*'.join(re.escape(char) for char in chars)
                pattern2 = r'\b' + spaced_pattern + r'\b'
                text = re.sub(pattern2, preserved_form, text, flags=re.IGNORECASE)
        
        return text

    # ===== IMPROVED WORD COMBINATION FIXING =====
    def fix_common_combinations(self, text):
        """Perbaiki kombinasi kata yang sering dipisah"""
        # Normalize spacing terlebih dahulu
        text = re.sub(r'\s+', ' ', text).strip()
        
        # Urutkan kombinasi dari yang terpanjang ke terpendek
        sorted_combinations = sorted(self.common_combinations.items(), 
                                   key=lambda x: len(x[0]), reverse=True)
        
        for combination, replacement in sorted_combinations:
            # Gunakan regex untuk matching yang lebih fleksibel
            pattern = r'\b' + re.escape(combination) + r'\b'
            if re.search(pattern, text, re.IGNORECASE):
                text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)
        
        return text

    # ===== IMPROVED NUMBER REPLACEMENT =====
    def smart_number_replacement(self, text):
        """Ganti angka dengan huruf hanya untuk kata-kata tertentu, pertahankan brand names"""
        # Step 1: Preserve brand names dengan angka terlebih dahulu
        text = self.preserve_brand_names_in_text(text)
        
        # Step 2: Untuk kata lainnya, gunakan replacement berdasarkan strategi
        if self.number_replacement_strategy == 'aggressive':
            # Ganti semua angka kecuali dalam brand names yang sudah dipreserve
            words = text.split()
            processed_words = []
            
            for word in words:
                # Jika word adalah brand name yang dipreserve, skip
                if word in self.preserved_brands.values():
                    processed_words.append(word)
                    continue
                
                # Jika word mengandung angka dan bukan brand name, lakukan replacement
                if any(char.isdigit() for char in word) and not word.isdigit():
                    processed_word = ''
                    for char in word:
                        if char in self.number_map:
                            processed_word += self.number_map[char]
                        else:
                            processed_word += char
                    processed_words.append(processed_word)
                else:
                    processed_words.append(word)
            
            text = ' '.join(processed_words)
            
        elif self.number_replacement_strategy == 'smart':
            # Hanya ganti angka pada kata-kata leet speak yang diketahui
            for leet_word, normal_word in self.leet_speak_indonesia.items():
                text = re.sub(r'\b' + re.escape(leet_word) + r'\b', normal_word, text, flags=re.IGNORECASE)
            
        # 'preserve' strategy tidak melakukan apa-apa terhadap angka
        
        return text

    def comprehensive_number_replacement(self, text):
        """Ganti angka dengan huruf yang sesuai - VERSI DIPERBAIKI"""
        # Step 1: Handle domain numbers berdasarkan strategi
        text = self.preserve_common_domains(text)
        
        # Step 2: Preserve brand names dengan angka
        text = self.preserve_brand_names_in_text(text)
        
        # Step 3: Decode leet speak Indonesia
        text = self.decode_leet_speak_indonesia(text)
        
        # Step 4: Smart number replacement berdasarkan strategi
        text = self.smart_number_replacement(text)
        
        return text

    # ===== WORD RECONSTRUCTION METHODS =====
    def advanced_word_reconstruction(self, text):
        """Rekonstruksi yang lebih advanced dengan pattern matching - DIPERBAIKI"""
        # Pattern untuk kata yang sering dipisah - DIPERBAIKI
        separation_patterns = {
            # SGI88 variations - DIPERBAIKI
            r'\b(s)\s*(g)\s*(i)\s*(8)\s*(8)\b': 'sgi88',
            r'\b(s\s*g\s*i\s*8\s*8)\b': 'sgi88',
            r'\b(sg)\s*(i88)\b': 'sgi88',
            r'\b(sgi)\s*(88)\b': 'sgi88',
            
            # PSTOTO99 variations - DIPERBAIKI
            r'\b(p)\s*(s)\s*(t)\s*(o)\s*(t)\s*(o)\s*(9)\s*(9)\b': 'pstoto99',
            r'\b(p\s*s\s*t\s*o\s*t\s*o\s*9\s*9)\b': 'pstoto99',
            r'\b(pstoto)\s*(99)\b': 'pstoto99',
            r'\b(ps)\s*(toto)\s*(99)\b': 'pstoto99',
            
            # Togel62 variations - TAMBAHKAN
            r'\b(t)\s*(o)\s*(g)\s*(e)\s*(l)\s*(6)\s*(2)\b': 'togel62',
            r'\b(t\s*o\s*g\s*e\s*l\s*6\s*2)\b': 'togel62',
            r'\b(togel)\s*(62)\b': 'togel62',
            
            # Sendal4d variations - TAMBAHKAN
            r'\b(s)\s*(e)\s*(n)\s*(d)\s*(a)\s*(l)\s*(4)\s*(d)\b': 'sendal4d',
            r'\b(s\s*e\s*n\s*d\s*a\s*l\s*4\s*d)\b': 'sendal4d',
            r'\b(sendal)\s*(4d)\b': 'sendal4d',
            
            # Sekali4d variations - TAMBAHKAN
            r'\b(s)\s*(e)\s*(k)\s*(a)\s*(l)\s*(i)\s*(4)\s*(d)\b': 'sekali4d',
            r'\b(s\s*e\s*k\s*a\s*l\s*i\s*4\s*d)\b': 'sekali4d',
            r'\b(sekali)\s*(4d)\b': 'sekali4d',
            
            # Pulauwin variations
            r'\b(p)\s*(u)\s*(l)\s*(a)\s*(u)\s*(w)\s*(i)\s*(n)\b': 'pulauwin',
            r'\b(p\s*u\s*l\s*a\s*u\s*w\s*i\s*n)\b': 'pulauwin',
            r'\b(pula)\s*(uwin)\b': 'pulauwin',
            r'\b(pulau)\s*(win)\b': 'pulauwin',
            
            # Arwanatoto variations
            r'\b(a)\s*(r)\s*(w)\s*(a)\s*(n)\s*(a)\s*(t)\s*(o)\s*(t)\s*(o)\b': 'arwanatoto',
            r'\b(arwana)\s*(toto)\b': 'arwanatoto',
            
            # Garudahoki variations
            r'\b(g)\s*(a)\s*(r)\s*(u)\s*(d)\s*(a)\s*(h)\s*(o)\s*(k)\s*(i)\b': 'garudahoki',
            r'\b(garuda)\s*(hoki)\b': 'garudahoki',
        }
        
        for pattern, replacement in separation_patterns.items():
            text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)
        
        return text

    def detect_and_fix_word_separation(self, text):
        """Deteksi dan perbaiki pemisahan kata dengan algoritma yang lebih robust"""
        # Step 1: Fix common combinations first
        text = self.fix_common_combinations(text)
        
        # Step 2: Original algorithm
        words = text.split()
        if len(words) < 2:
            return text
        
        i = 0
        result_words = []
        
        while i < len(words):
            current_word = words[i]
            
            # Skip jika kata sudah panjang atau mengandung angka
            if len(current_word) > 3 or any(char.isdigit() for char in current_word):
                result_words.append(current_word)
                i += 1
                continue
            
            # Coba gabung dengan kata berikutnya
            if i + 1 < len(words):
                next_word = words[i + 1]
                combined = current_word + next_word
                combined_lower = combined.lower()
                
                # Cek apakah gabungan membentuk kata judol
                is_judol_word = any(
                    judol_word == combined_lower or 
                    judol_word.startswith(combined_lower) or
                    combined_lower.startswith(judol_word)
                    for judol_word in self.judol_words_for_reconstruction
                )
                
                if is_judol_word and len(combined) >= 4:
                    # Cari kata judol yang paling tepat
                    best_match = None
                    for judol_word in self.judol_words_for_reconstruction:
                        if judol_word.startswith(combined_lower) or combined_lower.startswith(judol_word):
                            best_match = judol_word
                            break
                    
                    if best_match:
                        result_words.append(best_match)
                        i += 2  # Skip kedua kata
                        continue
            
            result_words.append(current_word)
            i += 1
        
        return ' '.join(result_words)

    def reconstruct_separated_words(self, text):
        """Rekonstruksi kata yang sengaja dipisah seperti 'p u l a u w i n' atau 'pula uwin'"""
        words = text.split()
        
        if len(words) <= 1:
            return text
        
        reconstructed_words = []
        i = 0
        
        while i < len(words):
            current_word = words[i]
            
            # Coba gabung dengan kata berikutnya untuk membentuk kata judol
            combined = current_word
            j = i + 1
            found_combination = False
            
            while j <= len(words):
                # Cek kombinasi saat ini
                current_combination = ''.join(words[i:j])
                current_combination_lower = current_combination.lower()
                
                # Cek apakah kombinasi ini adalah kata judol atau bagian darinya
                is_judol_combination = any(
                    judol_word.startswith(current_combination_lower) or 
                    current_combination_lower in judol_word or
                    judol_word.startswith(current_combination_lower.replace(' ', ''))
                    for judol_word in self.judol_words_for_reconstruction
                )
                
                # Jika kombinasi membentuk kata judol yang lengkap
                exact_match = any(
                    judol_word == current_combination_lower.replace(' ', '')
                    for judol_word in self.judol_words_for_reconstruction
                )
                
                if exact_match:
                    # Found exact match! Gunakan kata judol yang benar
                    matched_word = next(
                        judol_word for judol_word in self.judol_words_for_reconstruction 
                        if judol_word == current_combination_lower.replace(' ', '')
                    )
                    reconstructed_words.append(matched_word)
                    i = j
                    found_combination = True
                    break
                elif is_judol_combination and j < len(words):
                    # Masih mungkin bisa digabung lebih lanjut
                    j += 1
                else:
                    # Tidak bisa digabung lebih lanjut
                    break
            
            if not found_combination:
                # Jika tidak ada kombinasi yang ditemukan, gunakan kata asli
                reconstructed_words.append(current_word)
                i += 1
        
        return ' '.join(reconstructed_words)

    # ===== LEET SPEAK DECODING =====
    def decode_leet_speak_indonesia(self, text):
        """Decode leet speak khusus bahasa Indonesia"""
        # Step 1: Replace known leet speak patterns
        for leet_word, normal_word in self.leet_speak_indonesia.items():
            text = re.sub(r'\b' + re.escape(leet_word) + r'\b', normal_word, text, flags=re.IGNORECASE)
        
        return text

    def smart_contextual_replacement(self, word):
        """Ganti angka dengan huruf berdasarkan konteks - HANYA untuk non-brand words"""
        # Jika word adalah brand name yang dipreserve, return asli
        if word.lower() in [brand.lower() for brand in self.preserved_brands.values()]:
            return word
        
        if not any(char.isdigit() for char in word) or word.isdigit():
            return word
        
        # Convert to lowercase untuk processing
        word_lower = word.lower()
        result = []
        i = 0
        
        while i < len(word_lower):
            char = word_lower[i]
            
            if char in self.number_map:
                # Special case untuk '7' (bisa 't' atau 'r')
                if char == '7':
                    # '7un9kad' -> 'rungkad' (7u -> ru)
                    if i + 1 < len(word_lower) and word_lower[i + 1] == 'u':
                        result.append('r')
                    else:
                        result.append('t')
                else:
                    result.append(self.number_map[char])
            else:
                result.append(char)
            i += 1
        
        return ''.join(result)

    def advanced_leet_decode(self, text):
        """Decode leet speak dengan algoritma yang lebih advanced"""
        words = text.split()
        decoded_words = []
        
        for word in words:
            # Skip jika sudah berupa brand yang di-preserve
            if word in self.preserved_brands.values():
                decoded_words.append(word)
                continue
            
            # Skip jika hanya angka
            if word.isdigit():
                decoded_words.append(word)
                continue
            
            # Coba decode dengan pattern yang diketahui dulu
            original_word = word
            word_lower = word.lower()
            
            # Decode known patterns
            for leet_pattern, normal_word in self.leet_speak_indonesia.items():
                if leet_pattern in word_lower:
                    word = word_lower.replace(leet_pattern, normal_word)
                    break
            
            # Jika masih ada angka dan BUKAN brand name, gunakan contextual replacement
            if any(char.isdigit() for char in word) and word_lower not in [brand.lower() for brand in self.preserved_brands.values()]:
                word = self.smart_contextual_replacement(word)
            
            decoded_words.append(word)
        
        return ' '.join(decoded_words)

    # ===== DOMAIN NUMBER HANDLING =====
    def handle_domain_numbers(self, text):
        """Handle angka di domain dengan strategi yang berbeda"""
        if self.domain_number_strategy == 'remove':
            for domain in self.judol_domains:
                pattern = r'\b(' + domain + r')(\d{2,3})\b'
                text = re.sub(pattern, r'\1', text, flags=re.IGNORECASE)
            
        elif self.domain_number_strategy == 'preserve':
            for domain in self.judol_domains:
                pattern = r'\b(' + domain + r')(\d{2,3})\b'
                text = re.sub(pattern, r'\1 \2', text, flags=re.IGNORECASE)
            
        elif self.domain_number_strategy == 'separate_token':
            for domain in self.judol_domains:
                pattern = r'\b(' + domain + r')(\d{2,3})\b'
                text = re.sub(pattern, r'\1 [DOMAIN_NUMBER]', text, flags=re.IGNORECASE)
            
        return text

    def preserve_common_domains(self, text):
        """Preserve common domain patterns yang mengandung angka"""
        return self.handle_domain_numbers(text)

    # ===== TEXT NORMALIZATION =====
    def normalize_case(self, text):
        """Normalisasi kapitalisasi"""
        return text.lower()

    def remove_stopwords_id(self, text):
        """Hapus stopwords bahasa Indonesia - GUNAKAN YANG SELEKTIF"""
        return self.selective_stopword_removal(text)

    def stem_text(self, text):
        """Stemming bahasa Indonesia"""
        return self.stemmer.stem(text)

    def remove_repeated_chars(self, text):
        """Kurangi karakter berulang berlebihan"""
        text = re.sub(r'([a-zA-Z])\1{2,}', r'\1\1', text)
        return text

    def handle_repeated_words(self, text):
        """Handle kata yang diulang-ulang"""
        text = re.sub(r'\b(\w+)(?:\s+\1\b)+', r'\1', text)
        return text

    # ===== SPACING CLEANING =====
    def fix_advanced_spacing(self, text):
        """Perbaiki spacing"""
        text = re.sub(r'\s+', ' ', text)
        return text.strip()

    # ===== SPECIAL CHARACTER CLEANING =====
    def clean_special_characters(self, text):
        """Bersihkan karakter khusus seperti @@ dan lainnya"""
        # Hapus karakter khusus seperti @@, **, dll
        text = re.sub(r'[@#\$%\^&\*\(\)_\+=\[\]\{\};:"\\|<>/~`]', ' ', text)
        # Hapus multiple spaces
        text = re.sub(r'\s+', ' ', text)
        return text.strip()

    # ===== IMPROVED CLEANING PIPELINE =====
    def clean_comprehensive(self, text, aggressive=True):
        """
        Pipeline cleaning komprehensif untuk teks judol - VERSI DIPERBAIKI
        """
        if not isinstance(text, str) or not text.strip():
            return ""
        
        # âœ… PERBAIKI: URUTAN YANG LEBIH OPTIMAL
        steps = [
            self.fix_encoding,
            self.remove_text_decorations,
            self.enhanced_character_normalization,
            self.clean_brackets_and_special_chars,
            self.handle_emoji_characters,
            self.clean_whitespace_characters,
            
            # âœ… FASE 1: Brand Recognition & Segmentation
            self.enhanced_brand_recognition,      # Kenali brand patterns
            self.improved_word_segmentation,      # Pisahkan kata yang menempel
            self.fix_brand_spacing,               # Pastikan spasi konsisten
            
            # âœ… FASE 2: Word Reconstruction  
            self.fix_common_combinations,         # Gabungkan kombinasi umum
            self.advanced_word_reconstruction,    # Rekonstruksi kata terpisah
            self.detect_and_fix_word_separation,  # Deteksi pemisahan kata
            self.reconstruct_separated_words,     # Rekonstruksi kata terpisah
            
            # âœ… FASE 3: Brand Preservation & Cleaning
            self.preserve_brand_names_in_text,    # âœ… DIPINDAH: Sekarang setelah reconstruction
            self.fix_specific_brand_patterns,     # Perbaiki pattern brand khusus
            
            # âœ… FASE 4: General Cleaning
            self.remove_urls,
            self.remove_phone_numbers,
            self.comprehensive_number_replacement,
            self.remove_special_chars,
            self.remove_repeated_chars,
            self.handle_repeated_words,
            self.normalize_case,
            self.fix_advanced_spacing,
            self.selective_stopword_removal,   # tambahkan di sini
            self.fix_spaced_letters_with_numbers, 
            self.fix_broken_alphanumeric,      # baru jalankan di sini
            self.stem_text,     
        ]
        
        # Add aggressive cleaning steps if enabled
        if aggressive:
            aggressive_steps = [
                self.selective_stopword_removal,
                self.stem_text,
                self.fix_advanced_spacing,
            ]
            steps.extend(aggressive_steps)
        
        # Execute cleaning pipeline
        cleaned_text = text
        print(f"Original: {text}")
        for step in steps:
            try:
                previous_text = cleaned_text
                cleaned_text = step(cleaned_text)
                
                # Debug: Cetak perubahan jika ada
                if previous_text != cleaned_text:
                    print(f"After {step.__name__}: {cleaned_text}")
                   
                    
                if not cleaned_text.strip():
                    return ""
            except Exception as e:
                print(f"Error in {step.__name__}: {e}")
                continue
                
        cleaned_text = self.preserve_brand_names_in_text(cleaned_text)

        print("-" * 100)
        return cleaned_text

    # ===== BATCH PROCESSING =====
    def clean_dataset(self, df, text_column='text', new_column='cleaned_text', aggressive=True):
        """
        Clean entire dataset
        
        Parameters:
        df (DataFrame): DataFrame pandas
        text_column (str): Nama kolom teks
        new_column (str): Nama kolom hasil cleaning
        aggressive (bool): Mode aggressive cleaning
        """
        tqdm.pandas(desc="Cleaning texts")
        df[new_column] = df[text_column].progress_apply(
            lambda x: self.clean_comprehensive(x, aggressive=aggressive)
        )
        
        return df

    # ===== ANALYSIS METHODS =====
    def analyze_cleaning_result(self, original_text, cleaned_text):
        """Analisis hasil cleaning"""
        analysis = {
            'original_length': len(original_text),
            'cleaned_length': len(cleaned_text),
            'reduction_ratio': round((len(original_text) - len(cleaned_text)) / len(original_text) * 100, 2) if original_text else 0,
            'original_words': len(original_text.split()),
            'cleaned_words': len(cleaned_text.split()),
            'contains_judol_keywords': self.contains_judol_keywords(cleaned_text)
        }
        return analysis

    def contains_judol_keywords(self, text):
        """Cek apakah teks mengandung kata kunci judol"""
        judol_keywords = [
            'situs', 'slot', 'judi', 'togel', 'poker', 'casino', 
            'taruhan', 'betting', 'deposit', 'withdraw', 'bonus',
            'jackpot', 'freespin', 'bandar', 'sabung', 'gambling',
            'pstoto', 'toto', 'arwana', 'pulauwin', 'lazadatoto',
            'insan4d', 'paste4d', 'pandora4d', 'bosan', 'rungkad',
            'sendal4d', 'garudahoki', 'togel62', 'arwanatoto', 'pstoto99',
            'sgi88', 'sg188', 'sgi808', 'sgi888', 'sekali4d'  # TAMBAHKAN SEKALI4D
        ]
        
        text_lower = text.lower()
        found_keywords = [keyword for keyword in judol_keywords if keyword in text_lower]
        return len(found_keywords) > 0, found_keywords


df = pd.read_csv('comments_from_scraping.csv')

cleaner = JudolTextCleaner()
 
for i, text in enumerate(df["comment_text"], 1):
    cleaned = cleaner.clean_comprehensive(text)
    
    df.loc[i-1, "comment_text"] = cleaned


empty_comments = df[df['comment_text'].str.strip() == '']
print(f"Jumlah komentar yang kosong: {len(empty_comments)}")
print(f"Persentase: {(len(empty_comments) / len(df)) * 100:.2f}%")



df = df[df['comment_text'].str.strip().astype(bool)].reset_index(drop=True)

output_filename = 'cleaned_comments.csv'
columns_to_save = [
    col for col in [
        'Unnamed: 0', 'comment_id', 'video_id', 'author', 
        'comment_text', 'published_at', 'like_count'
    ] if col in df.columns
]



df[columns_to_save].to_csv(output_filename, index=False, encoding='utf-8')
print(f"\nâœ… Data ultimate disimpan ke: {output_filename}")
print(f"ðŸ“Š Total baris: {len(df)}")

