{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59146de3-408e-4966-ab7e-6f318e9734a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/wtf/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "/home/wtf/anaconda3/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['baiknya', 'berkali', 'kali', 'kurangnya', 'mata', 'olah', 'sekurang', 'setidak', 'tama', 'tidaknya'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.013\n",
      "\n",
      "=== Analisis Tiap Cluster ===\n",
      "\n",
      "Cluster 0 (jumlah: 136)\n",
      "Top keywords: [('banget', 140), ('se', 31), ('yang', 17), ('kyt4d', 17), ('ini', 17), ('pulauwin', 17), ('lucu', 15), ('suka', 15), ('sama', 14), ('ambil4d', 14)]\n",
      "Contoh: ['sumpah pak jarwo lucu banget njiirtt', 'aduh ken banget', 'roma se rem banget dah', 'bener bener rejeki nomplok money mouth face tkp62 juara banget', 'mantap seru banget nonton channel probet 855 minat ramee']\n",
      "\n",
      "Cluster 1 (jumlah: 1676)\n",
      "Top keywords: [('se', 445), ('yang', 144), ('ini', 135), ('yg', 129), ('ada', 122), ('itu', 120), ('kucing', 118), ('gak', 116), ('ya', 98), ('jok', 88)]\n",
      "Contoh: ['my mom never do that for me', 'ada jaitan a gtu rawan bocor air saat musim ujan', 'yapp ini jelas paling realistis gabisa debat lagi perfect bro gas google se karang ambil4d', 'itu captionnya gmna dah gwe bingung yg ngedit slah tik atau gmna udah gwe ulang2 baca msih bingung', 'kirain pegang roti td awal']\n",
      "\n",
      "Cluster 2 (jumlah: 202)\n",
      "Top keywords: [('bang', 225), ('bisa', 28), ('jok', 24), ('buat', 23), ('ada', 23), ('mana', 22), ('lokasi', 21), ('berapa', 21), ('se', 18), ('kalo', 16)]\n",
      "Contoh: ['lokasi d mana bang', 'halo bang praz', 'buat untuk honda revo lama 2007 bisa bang', 'tawa bang pras renyah banget', 'pertama bang xin']\n",
      "\n",
      "Disimpan ke hasil_clustering_judol_full.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Unduh stopwords Indo (pertama kali aja)\n",
    "nltk.download('stopwords')\n",
    "indo_stopwords = stopwords.words('indonesian')\n",
    "\n",
    "# === Load dataset ===\n",
    "df_main = pd.read_csv(\"labeled_comments_ultimate.csv\")\n",
    "text_col = \"text\" if \"text\" in df_main.columns else df_main.columns[0]\n",
    "df_main = df_main[[text_col]].rename(columns={text_col: \"komentar\"})\n",
    "\n",
    "# === Tambahan data baru ===\n",
    "df_extra = pd.DataFrame({\n",
    "    \"komentar\": [\n",
    "        \"main di web biru lagi rame banget\",\n",
    "        \"aku baru beli hp di shopee\",\n",
    "        \"spin scatter muncul tiga kali\",\n",
    "        \"tadi malam hoki banget dapet jackpot\",\n",
    "        \"modal receh tapi jadi banyak\",\n",
    "        \"videonya lucu banget parah ðŸ˜‚\",\n",
    "        \"situs itu emang rame tiap malam\",\n",
    "        \"saldo digital tiba-tiba nambah\",\n",
    "        \"kualitas suaranya keren banget\",\n",
    "        \"berita hari ini tentang slot lagi viral\"\n",
    "    ]\n",
    "})\n",
    "df_all = pd.concat([df_main, df_extra], ignore_index=True)\n",
    "\n",
    "# === TF-IDF Vectorizer ===\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    ngram_range=(1,2),\n",
    "    stop_words=indo_stopwords\n",
    ")\n",
    "X = vectorizer.fit_transform(df_all[\"komentar\"].astype(str))\n",
    "\n",
    "# === KMeans Clustering ===\n",
    "k = 3\n",
    "kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "df_all[\"cluster\"] = kmeans.fit_predict(X)\n",
    "\n",
    "# === Evaluasi dan Analisis ===\n",
    "score = silhouette_score(X, df_all[\"cluster\"])\n",
    "print(f\"Silhouette Score: {score:.3f}\")\n",
    "\n",
    "print(\"\\n=== Analisis Tiap Cluster ===\")\n",
    "for i in range(k):\n",
    "    subset = df_all[df_all[\"cluster\"] == i]\n",
    "    keywords = Counter(\" \".join(subset[\"komentar\"]).lower().split()).most_common(10)\n",
    "    print(f\"\\nCluster {i} (jumlah: {len(subset)})\")\n",
    "    print(\"Top keywords:\", keywords)\n",
    "    print(\"Contoh:\", subset[\"komentar\"].sample(min(5, len(subset))).tolist())\n",
    "\n",
    "df_all.to_csv(\"hasil_clustering_judol_full.csv\", index=False)\n",
    "print(\"\\nDisimpan ke hasil_clustering_judol_full.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251b3323-aa51-45fb-acc0-29bbbb0e4058",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
